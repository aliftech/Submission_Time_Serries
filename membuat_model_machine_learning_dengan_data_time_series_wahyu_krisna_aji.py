# -*- coding: utf-8 -*-
"""Membuat Model Machine Learning dengan Data Time Series Wahyu Krisna Aji.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-Rsy_B63UjajgK1GiMshlnrXros9WsXV

Nama: Wahyu Krisna Aji

Dataset: Apple Stock Price from 1980-2021

Source of Dataset: Kaggle

Link Dataset: https://www.kaggle.com/datasets/meetnagadia/apple-stock-price-from-19802021
"""

import numpy as np
import pandas as pd
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split

data = pd.read_csv('AAPL.csv')
data

data.isnull().sum()

data = data[['Date', 'Close']]

data.head()

data.info()

mae_rate = (data['Close'].max() - data['Close'].min()) * 10/100
print(mae_rate)

Date = data['Date'].values
Price = data['Close'].values

plt.figure(figsize=(20,8))
plt.plot(Date, Price)
plt.title('Apple Stock Price from 1980 - 2021')
plt.xlabel('Date')
plt.ylabel('Price')
plt.show()

x_train, x_test, y_train, y_test = train_test_split(Price, Date, test_size = 0.2)

print('Jumlah Data Latih : ',len(x_train))
print('Jumah Data Validasi : ',len(x_test))

#  Function untuk mengubah data menjadi dapat dibaca oleh model
def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
  series = tf.expand_dims(series, axis=-1)
  data_series = tf.data.Dataset.from_tensor_slices(series)
  data_series = data_series.window(window_size + 1, shift=1, drop_remainder = True)
  data_series = data_series.flat_map(lambda w: w.batch(window_size + 1))
  data_series = data_series.shuffle(shuffle_buffer)
  data_series = data_series.map(lambda w: (w[:-1], w[-1:]))
  return data_series.batch(batch_size).prefetch(1)

data_training = windowed_dataset(x_train, window_size=64, batch_size=128, shuffle_buffer=1000)
data_testing = windowed_dataset(x_test, window_size=64, batch_size=128, shuffle_buffer=1000)

model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(64, return_sequences=True),
  tf.keras.layers.LSTM(64),
  tf.keras.layers.Dense(30, activation="relu"),
  tf.keras.layers.Dropout(0.5),
  tf.keras.layers.Dense(10, activation="relu"),
  tf.keras.layers.Dropout(0.5),
  tf.keras.layers.Dense(1),
])

optimizers = tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizers,
              metrics=["mae"])
model_history = model.fit(
    data_training,
    epochs=50, 
    validation_data=data_testing, 
)